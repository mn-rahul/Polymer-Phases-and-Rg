{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.20243</td>\n",
       "      <td>-0.574106</td>\n",
       "      <td>-6.78421</td>\n",
       "      <td>-2.43637</td>\n",
       "      <td>-2.28676</td>\n",
       "      <td>-1.061320</td>\n",
       "      <td>-1.396050</td>\n",
       "      <td>-6.18320</td>\n",
       "      <td>-6.93734</td>\n",
       "      <td>-6.75859</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.66383</td>\n",
       "      <td>-5.69793</td>\n",
       "      <td>-6.76522</td>\n",
       "      <td>-6.14721</td>\n",
       "      <td>-6.92017</td>\n",
       "      <td>-6.38389</td>\n",
       "      <td>-6.08320</td>\n",
       "      <td>-6.74807</td>\n",
       "      <td>-6.12753</td>\n",
       "      <td>-6.09497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.78500</td>\n",
       "      <td>-0.444601</td>\n",
       "      <td>-6.08639</td>\n",
       "      <td>-2.31255</td>\n",
       "      <td>-1.46379</td>\n",
       "      <td>-0.451503</td>\n",
       "      <td>-1.108550</td>\n",
       "      <td>-5.79833</td>\n",
       "      <td>-5.95591</td>\n",
       "      <td>-7.01259</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.57356</td>\n",
       "      <td>-6.20284</td>\n",
       "      <td>-6.60527</td>\n",
       "      <td>-6.45421</td>\n",
       "      <td>-6.22176</td>\n",
       "      <td>-5.91659</td>\n",
       "      <td>-5.77094</td>\n",
       "      <td>-6.54771</td>\n",
       "      <td>-5.69566</td>\n",
       "      <td>-5.36605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.71998</td>\n",
       "      <td>-1.828610</td>\n",
       "      <td>-6.50998</td>\n",
       "      <td>-1.98596</td>\n",
       "      <td>-1.42878</td>\n",
       "      <td>-0.590429</td>\n",
       "      <td>-0.403125</td>\n",
       "      <td>-5.99940</td>\n",
       "      <td>-5.67518</td>\n",
       "      <td>-5.72028</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.03319</td>\n",
       "      <td>-7.01264</td>\n",
       "      <td>-6.84003</td>\n",
       "      <td>-6.54604</td>\n",
       "      <td>-5.70527</td>\n",
       "      <td>-6.73675</td>\n",
       "      <td>-5.20082</td>\n",
       "      <td>-5.63525</td>\n",
       "      <td>-5.99084</td>\n",
       "      <td>-4.69566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.88735</td>\n",
       "      <td>-1.715090</td>\n",
       "      <td>-6.08733</td>\n",
       "      <td>-1.78564</td>\n",
       "      <td>-1.08051</td>\n",
       "      <td>-0.634591</td>\n",
       "      <td>-0.414766</td>\n",
       "      <td>-6.27433</td>\n",
       "      <td>-5.29611</td>\n",
       "      <td>-5.67247</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.64745</td>\n",
       "      <td>-6.87816</td>\n",
       "      <td>-6.81495</td>\n",
       "      <td>-6.72227</td>\n",
       "      <td>-4.36778</td>\n",
       "      <td>-6.76653</td>\n",
       "      <td>-4.59964</td>\n",
       "      <td>-5.49961</td>\n",
       "      <td>-6.53587</td>\n",
       "      <td>-3.88017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.16550</td>\n",
       "      <td>-1.917750</td>\n",
       "      <td>-6.40865</td>\n",
       "      <td>-1.94179</td>\n",
       "      <td>-1.54037</td>\n",
       "      <td>-1.267810</td>\n",
       "      <td>-1.117900</td>\n",
       "      <td>-5.87232</td>\n",
       "      <td>-5.36341</td>\n",
       "      <td>-4.64141</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.04762</td>\n",
       "      <td>-7.14228</td>\n",
       "      <td>-6.56706</td>\n",
       "      <td>-6.63142</td>\n",
       "      <td>-4.05589</td>\n",
       "      <td>-6.36894</td>\n",
       "      <td>-3.36560</td>\n",
       "      <td>-6.02235</td>\n",
       "      <td>-7.32030</td>\n",
       "      <td>-3.83486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1        2        3        4         5         6        7    \\\n",
       "0 -2.20243 -0.574106 -6.78421 -2.43637 -2.28676 -1.061320 -1.396050 -6.18320   \n",
       "1 -1.78500 -0.444601 -6.08639 -2.31255 -1.46379 -0.451503 -1.108550 -5.79833   \n",
       "2 -2.71998 -1.828610 -6.50998 -1.98596 -1.42878 -0.590429 -0.403125 -5.99940   \n",
       "3 -2.88735 -1.715090 -6.08733 -1.78564 -1.08051 -0.634591 -0.414766 -6.27433   \n",
       "4 -2.16550 -1.917750 -6.40865 -1.94179 -1.54037 -1.267810 -1.117900 -5.87232   \n",
       "\n",
       "       8        9    ...      290      291      292      293      294  \\\n",
       "0 -6.93734 -6.75859  ... -6.66383 -5.69793 -6.76522 -6.14721 -6.92017   \n",
       "1 -5.95591 -7.01259  ... -5.57356 -6.20284 -6.60527 -6.45421 -6.22176   \n",
       "2 -5.67518 -5.72028  ... -6.03319 -7.01264 -6.84003 -6.54604 -5.70527   \n",
       "3 -5.29611 -5.67247  ... -5.64745 -6.87816 -6.81495 -6.72227 -4.36778   \n",
       "4 -5.36341 -4.64141  ... -6.04762 -7.14228 -6.56706 -6.63142 -4.05589   \n",
       "\n",
       "       295      296      297      298      299  \n",
       "0 -6.38389 -6.08320 -6.74807 -6.12753 -6.09497  \n",
       "1 -5.91659 -5.77094 -6.54771 -5.69566 -5.36605  \n",
       "2 -6.73675 -5.20082 -5.63525 -5.99084 -4.69566  \n",
       "3 -6.76653 -4.59964 -5.49961 -6.53587 -3.88017  \n",
       "4 -6.36894 -3.36560 -6.02235 -7.32030 -3.83486  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data_clust.csv', header=None)\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1019.774302\n",
       "1        1168.219219\n",
       "2        1243.485521\n",
       "3        1317.552985\n",
       "4        1368.857216\n",
       "            ...     \n",
       "12055     155.223806\n",
       "12056     150.341157\n",
       "12057     147.113192\n",
       "12058     129.499981\n",
       "12059     134.753937\n",
       "Length: 12060, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx=df.iloc[:,0:100]\n",
    "dfx.shape\n",
    "xmean=dfx.mean(axis=1)\n",
    "xmean\n",
    "diffx=dfx.subtract(xmean, axis=0)\n",
    "diffx=diffx**2\n",
    "#diffx.head(5)\n",
    "diffxsum=diffx.sum(axis=1)\n",
    "diffxsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        653.429338\n",
       "1        692.565443\n",
       "2        708.164262\n",
       "3        744.414175\n",
       "4        768.363399\n",
       "            ...    \n",
       "12055    229.752449\n",
       "12056    242.608370\n",
       "12057    241.769194\n",
       "12058    227.828465\n",
       "12059    248.549972\n",
       "Length: 12060, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfy=df.iloc[:,100:200]\n",
    "dfy.shape\n",
    "ymean=dfy.mean(axis=1)\n",
    "ymean\n",
    "diffy=dfy.subtract(ymean, axis=0)\n",
    "diffy=diffy**2\n",
    "#diffy.head(5)\n",
    "diffysum=diffy.sum(axis=1)\n",
    "diffysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        798.131216\n",
       "1        769.254701\n",
       "2        742.479524\n",
       "3        688.336594\n",
       "4        662.983888\n",
       "            ...    \n",
       "12055    183.225411\n",
       "12056    174.860111\n",
       "12057    190.978607\n",
       "12058    204.162998\n",
       "12059    222.051912\n",
       "Length: 12060, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfz=df.iloc[:,200:300]\n",
    "dfz.shape\n",
    "zmean=dfz.mean(axis=1)\n",
    "zmean\n",
    "diffz=dfz.subtract(zmean,axis=0)\n",
    "diffz = diffz**2\n",
    "# diffz.head(5)\n",
    "diffzsum=diffz.sum(axis=1)\n",
    "diffzsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.971252\n",
       "1        5.128391\n",
       "2        5.190500\n",
       "3        5.244334\n",
       "4        5.291696\n",
       "           ...   \n",
       "12055    2.383698\n",
       "12056    2.382876\n",
       "12057    2.408030\n",
       "12058    2.369581\n",
       "12059    2.460398\n",
       "Name: Rg, Length: 12060, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temdf=pd.DataFrame([diffxsum,diffysum,diffzsum])\n",
    "temdf=temdf.T\n",
    "temdf['Rg']=temdf.sum(axis=1)\n",
    "Rg=np.sqrt(temdf['Rg']/100)\n",
    "Rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rg']=Rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Rg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.20243</td>\n",
       "      <td>-0.574106</td>\n",
       "      <td>-6.78421</td>\n",
       "      <td>-2.43637</td>\n",
       "      <td>-2.28676</td>\n",
       "      <td>-1.061320</td>\n",
       "      <td>-1.396050</td>\n",
       "      <td>-6.18320</td>\n",
       "      <td>-6.93734</td>\n",
       "      <td>-6.75859</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.69793</td>\n",
       "      <td>-6.76522</td>\n",
       "      <td>-6.14721</td>\n",
       "      <td>-6.92017</td>\n",
       "      <td>-6.38389</td>\n",
       "      <td>-6.08320</td>\n",
       "      <td>-6.74807</td>\n",
       "      <td>-6.12753</td>\n",
       "      <td>-6.09497</td>\n",
       "      <td>4.971252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.78500</td>\n",
       "      <td>-0.444601</td>\n",
       "      <td>-6.08639</td>\n",
       "      <td>-2.31255</td>\n",
       "      <td>-1.46379</td>\n",
       "      <td>-0.451503</td>\n",
       "      <td>-1.108550</td>\n",
       "      <td>-5.79833</td>\n",
       "      <td>-5.95591</td>\n",
       "      <td>-7.01259</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.20284</td>\n",
       "      <td>-6.60527</td>\n",
       "      <td>-6.45421</td>\n",
       "      <td>-6.22176</td>\n",
       "      <td>-5.91659</td>\n",
       "      <td>-5.77094</td>\n",
       "      <td>-6.54771</td>\n",
       "      <td>-5.69566</td>\n",
       "      <td>-5.36605</td>\n",
       "      <td>5.128391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.71998</td>\n",
       "      <td>-1.828610</td>\n",
       "      <td>-6.50998</td>\n",
       "      <td>-1.98596</td>\n",
       "      <td>-1.42878</td>\n",
       "      <td>-0.590429</td>\n",
       "      <td>-0.403125</td>\n",
       "      <td>-5.99940</td>\n",
       "      <td>-5.67518</td>\n",
       "      <td>-5.72028</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.01264</td>\n",
       "      <td>-6.84003</td>\n",
       "      <td>-6.54604</td>\n",
       "      <td>-5.70527</td>\n",
       "      <td>-6.73675</td>\n",
       "      <td>-5.20082</td>\n",
       "      <td>-5.63525</td>\n",
       "      <td>-5.99084</td>\n",
       "      <td>-4.69566</td>\n",
       "      <td>5.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.88735</td>\n",
       "      <td>-1.715090</td>\n",
       "      <td>-6.08733</td>\n",
       "      <td>-1.78564</td>\n",
       "      <td>-1.08051</td>\n",
       "      <td>-0.634591</td>\n",
       "      <td>-0.414766</td>\n",
       "      <td>-6.27433</td>\n",
       "      <td>-5.29611</td>\n",
       "      <td>-5.67247</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.87816</td>\n",
       "      <td>-6.81495</td>\n",
       "      <td>-6.72227</td>\n",
       "      <td>-4.36778</td>\n",
       "      <td>-6.76653</td>\n",
       "      <td>-4.59964</td>\n",
       "      <td>-5.49961</td>\n",
       "      <td>-6.53587</td>\n",
       "      <td>-3.88017</td>\n",
       "      <td>5.244334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.16550</td>\n",
       "      <td>-1.917750</td>\n",
       "      <td>-6.40865</td>\n",
       "      <td>-1.94179</td>\n",
       "      <td>-1.54037</td>\n",
       "      <td>-1.267810</td>\n",
       "      <td>-1.117900</td>\n",
       "      <td>-5.87232</td>\n",
       "      <td>-5.36341</td>\n",
       "      <td>-4.64141</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.14228</td>\n",
       "      <td>-6.56706</td>\n",
       "      <td>-6.63142</td>\n",
       "      <td>-4.05589</td>\n",
       "      <td>-6.36894</td>\n",
       "      <td>-3.36560</td>\n",
       "      <td>-6.02235</td>\n",
       "      <td>-7.32030</td>\n",
       "      <td>-3.83486</td>\n",
       "      <td>5.291696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>-22.47340</td>\n",
       "      <td>-21.776700</td>\n",
       "      <td>-22.54490</td>\n",
       "      <td>-22.33940</td>\n",
       "      <td>-19.83900</td>\n",
       "      <td>-20.392100</td>\n",
       "      <td>-19.686600</td>\n",
       "      <td>-21.24140</td>\n",
       "      <td>-21.00190</td>\n",
       "      <td>-21.16530</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.45580</td>\n",
       "      <td>-18.58520</td>\n",
       "      <td>-18.94890</td>\n",
       "      <td>-20.48770</td>\n",
       "      <td>-20.40950</td>\n",
       "      <td>-18.88740</td>\n",
       "      <td>-19.46130</td>\n",
       "      <td>-18.39660</td>\n",
       "      <td>-18.30520</td>\n",
       "      <td>2.383698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>-22.14180</td>\n",
       "      <td>-22.228700</td>\n",
       "      <td>-22.22860</td>\n",
       "      <td>-22.86550</td>\n",
       "      <td>-19.67470</td>\n",
       "      <td>-20.334300</td>\n",
       "      <td>-19.714500</td>\n",
       "      <td>-21.29140</td>\n",
       "      <td>-21.08730</td>\n",
       "      <td>-21.25140</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.85070</td>\n",
       "      <td>-18.84070</td>\n",
       "      <td>-19.51340</td>\n",
       "      <td>-20.50450</td>\n",
       "      <td>-21.11590</td>\n",
       "      <td>-18.96670</td>\n",
       "      <td>-19.40030</td>\n",
       "      <td>-18.55570</td>\n",
       "      <td>-17.93220</td>\n",
       "      <td>2.382876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>-21.52850</td>\n",
       "      <td>-22.391400</td>\n",
       "      <td>-22.46900</td>\n",
       "      <td>-23.27930</td>\n",
       "      <td>-20.00960</td>\n",
       "      <td>-20.286100</td>\n",
       "      <td>-19.809600</td>\n",
       "      <td>-21.42910</td>\n",
       "      <td>-21.06020</td>\n",
       "      <td>-21.43580</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.47800</td>\n",
       "      <td>-19.92470</td>\n",
       "      <td>-19.55950</td>\n",
       "      <td>-20.35020</td>\n",
       "      <td>-21.24480</td>\n",
       "      <td>-19.02260</td>\n",
       "      <td>-18.59210</td>\n",
       "      <td>-18.41880</td>\n",
       "      <td>-17.84070</td>\n",
       "      <td>2.408030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12058</th>\n",
       "      <td>-21.31210</td>\n",
       "      <td>-22.158700</td>\n",
       "      <td>-22.70210</td>\n",
       "      <td>-23.06870</td>\n",
       "      <td>-20.49630</td>\n",
       "      <td>-20.664200</td>\n",
       "      <td>-19.869000</td>\n",
       "      <td>-21.53460</td>\n",
       "      <td>-20.85500</td>\n",
       "      <td>-20.74480</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.78800</td>\n",
       "      <td>-20.01190</td>\n",
       "      <td>-19.79120</td>\n",
       "      <td>-20.65320</td>\n",
       "      <td>-21.37940</td>\n",
       "      <td>-18.73010</td>\n",
       "      <td>-18.38590</td>\n",
       "      <td>-18.02740</td>\n",
       "      <td>-17.17300</td>\n",
       "      <td>2.369581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>-21.13920</td>\n",
       "      <td>-22.311300</td>\n",
       "      <td>-22.87210</td>\n",
       "      <td>-22.58910</td>\n",
       "      <td>-20.36390</td>\n",
       "      <td>-20.403300</td>\n",
       "      <td>-19.946200</td>\n",
       "      <td>-21.24030</td>\n",
       "      <td>-21.56010</td>\n",
       "      <td>-20.85170</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.47910</td>\n",
       "      <td>-19.26840</td>\n",
       "      <td>-19.55480</td>\n",
       "      <td>-20.83860</td>\n",
       "      <td>-21.82330</td>\n",
       "      <td>-18.97790</td>\n",
       "      <td>-18.31500</td>\n",
       "      <td>-17.83690</td>\n",
       "      <td>-17.21560</td>\n",
       "      <td>2.460398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12060 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1         2         3         4          5  \\\n",
       "0      -2.20243  -0.574106  -6.78421  -2.43637  -2.28676  -1.061320   \n",
       "1      -1.78500  -0.444601  -6.08639  -2.31255  -1.46379  -0.451503   \n",
       "2      -2.71998  -1.828610  -6.50998  -1.98596  -1.42878  -0.590429   \n",
       "3      -2.88735  -1.715090  -6.08733  -1.78564  -1.08051  -0.634591   \n",
       "4      -2.16550  -1.917750  -6.40865  -1.94179  -1.54037  -1.267810   \n",
       "...         ...        ...       ...       ...       ...        ...   \n",
       "12055 -22.47340 -21.776700 -22.54490 -22.33940 -19.83900 -20.392100   \n",
       "12056 -22.14180 -22.228700 -22.22860 -22.86550 -19.67470 -20.334300   \n",
       "12057 -21.52850 -22.391400 -22.46900 -23.27930 -20.00960 -20.286100   \n",
       "12058 -21.31210 -22.158700 -22.70210 -23.06870 -20.49630 -20.664200   \n",
       "12059 -21.13920 -22.311300 -22.87210 -22.58910 -20.36390 -20.403300   \n",
       "\n",
       "               6         7         8         9  ...       291       292  \\\n",
       "0      -1.396050  -6.18320  -6.93734  -6.75859  ...  -5.69793  -6.76522   \n",
       "1      -1.108550  -5.79833  -5.95591  -7.01259  ...  -6.20284  -6.60527   \n",
       "2      -0.403125  -5.99940  -5.67518  -5.72028  ...  -7.01264  -6.84003   \n",
       "3      -0.414766  -6.27433  -5.29611  -5.67247  ...  -6.87816  -6.81495   \n",
       "4      -1.117900  -5.87232  -5.36341  -4.64141  ...  -7.14228  -6.56706   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "12055 -19.686600 -21.24140 -21.00190 -21.16530  ... -18.45580 -18.58520   \n",
       "12056 -19.714500 -21.29140 -21.08730 -21.25140  ... -17.85070 -18.84070   \n",
       "12057 -19.809600 -21.42910 -21.06020 -21.43580  ... -17.47800 -19.92470   \n",
       "12058 -19.869000 -21.53460 -20.85500 -20.74480  ... -17.78800 -20.01190   \n",
       "12059 -19.946200 -21.24030 -21.56010 -20.85170  ... -17.47910 -19.26840   \n",
       "\n",
       "            293       294       295       296       297       298       299  \\\n",
       "0      -6.14721  -6.92017  -6.38389  -6.08320  -6.74807  -6.12753  -6.09497   \n",
       "1      -6.45421  -6.22176  -5.91659  -5.77094  -6.54771  -5.69566  -5.36605   \n",
       "2      -6.54604  -5.70527  -6.73675  -5.20082  -5.63525  -5.99084  -4.69566   \n",
       "3      -6.72227  -4.36778  -6.76653  -4.59964  -5.49961  -6.53587  -3.88017   \n",
       "4      -6.63142  -4.05589  -6.36894  -3.36560  -6.02235  -7.32030  -3.83486   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12055 -18.94890 -20.48770 -20.40950 -18.88740 -19.46130 -18.39660 -18.30520   \n",
       "12056 -19.51340 -20.50450 -21.11590 -18.96670 -19.40030 -18.55570 -17.93220   \n",
       "12057 -19.55950 -20.35020 -21.24480 -19.02260 -18.59210 -18.41880 -17.84070   \n",
       "12058 -19.79120 -20.65320 -21.37940 -18.73010 -18.38590 -18.02740 -17.17300   \n",
       "12059 -19.55480 -20.83860 -21.82330 -18.97790 -18.31500 -17.83690 -17.21560   \n",
       "\n",
       "             Rg  \n",
       "0      4.971252  \n",
       "1      5.128391  \n",
       "2      5.190500  \n",
       "3      5.244334  \n",
       "4      5.291696  \n",
       "...         ...  \n",
       "12055  2.383698  \n",
       "12056  2.382876  \n",
       "12057  2.408030  \n",
       "12058  2.369581  \n",
       "12059  2.460398  \n",
       "\n",
       "[12060 rows x 301 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data_reg.csv')\n",
    "data=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710591</td>\n",
       "      <td>0.740873</td>\n",
       "      <td>0.547199</td>\n",
       "      <td>0.741455</td>\n",
       "      <td>0.773017</td>\n",
       "      <td>0.802497</td>\n",
       "      <td>0.744242</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.589981</td>\n",
       "      <td>0.634474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600817</td>\n",
       "      <td>0.554528</td>\n",
       "      <td>0.549675</td>\n",
       "      <td>0.525217</td>\n",
       "      <td>0.539929</td>\n",
       "      <td>0.551142</td>\n",
       "      <td>0.513436</td>\n",
       "      <td>0.544774</td>\n",
       "      <td>0.549715</td>\n",
       "      <td>0.328776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.723895</td>\n",
       "      <td>0.744900</td>\n",
       "      <td>0.569207</td>\n",
       "      <td>0.745544</td>\n",
       "      <td>0.800938</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.753272</td>\n",
       "      <td>0.592454</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.626670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583271</td>\n",
       "      <td>0.560188</td>\n",
       "      <td>0.538886</td>\n",
       "      <td>0.550928</td>\n",
       "      <td>0.555804</td>\n",
       "      <td>0.562092</td>\n",
       "      <td>0.520488</td>\n",
       "      <td>0.560097</td>\n",
       "      <td>0.575321</td>\n",
       "      <td>0.348507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.694096</td>\n",
       "      <td>0.701866</td>\n",
       "      <td>0.555848</td>\n",
       "      <td>0.756330</td>\n",
       "      <td>0.802126</td>\n",
       "      <td>0.818500</td>\n",
       "      <td>0.775430</td>\n",
       "      <td>0.586418</td>\n",
       "      <td>0.631961</td>\n",
       "      <td>0.666377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555129</td>\n",
       "      <td>0.551880</td>\n",
       "      <td>0.535658</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>0.527941</td>\n",
       "      <td>0.582085</td>\n",
       "      <td>0.552601</td>\n",
       "      <td>0.549623</td>\n",
       "      <td>0.598872</td>\n",
       "      <td>0.356306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.688762</td>\n",
       "      <td>0.705396</td>\n",
       "      <td>0.569178</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>0.813941</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.775064</td>\n",
       "      <td>0.578164</td>\n",
       "      <td>0.644569</td>\n",
       "      <td>0.667846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>0.552768</td>\n",
       "      <td>0.529465</td>\n",
       "      <td>0.619179</td>\n",
       "      <td>0.526930</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>0.557375</td>\n",
       "      <td>0.530285</td>\n",
       "      <td>0.627519</td>\n",
       "      <td>0.363066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.711768</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.559043</td>\n",
       "      <td>0.757788</td>\n",
       "      <td>0.798340</td>\n",
       "      <td>0.795479</td>\n",
       "      <td>0.752978</td>\n",
       "      <td>0.590233</td>\n",
       "      <td>0.642330</td>\n",
       "      <td>0.699525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550624</td>\n",
       "      <td>0.561540</td>\n",
       "      <td>0.532658</td>\n",
       "      <td>0.630660</td>\n",
       "      <td>0.540437</td>\n",
       "      <td>0.646442</td>\n",
       "      <td>0.538977</td>\n",
       "      <td>0.502453</td>\n",
       "      <td>0.629111</td>\n",
       "      <td>0.369014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.084155</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>0.145549</td>\n",
       "      <td>0.169727</td>\n",
       "      <td>0.128819</td>\n",
       "      <td>0.122197</td>\n",
       "      <td>0.191824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157467</td>\n",
       "      <td>0.136246</td>\n",
       "      <td>0.099779</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.102131</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>0.109455</td>\n",
       "      <td>0.120781</td>\n",
       "      <td>0.003857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>0.075095</td>\n",
       "      <td>0.067554</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>0.066780</td>\n",
       "      <td>0.183105</td>\n",
       "      <td>0.147513</td>\n",
       "      <td>0.168850</td>\n",
       "      <td>0.127318</td>\n",
       "      <td>0.119356</td>\n",
       "      <td>0.189179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.127205</td>\n",
       "      <td>0.079941</td>\n",
       "      <td>0.025132</td>\n",
       "      <td>0.039449</td>\n",
       "      <td>0.099350</td>\n",
       "      <td>0.068147</td>\n",
       "      <td>0.103810</td>\n",
       "      <td>0.133884</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>0.094642</td>\n",
       "      <td>0.062495</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.171743</td>\n",
       "      <td>0.149151</td>\n",
       "      <td>0.165863</td>\n",
       "      <td>0.123184</td>\n",
       "      <td>0.120258</td>\n",
       "      <td>0.183513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191447</td>\n",
       "      <td>0.088844</td>\n",
       "      <td>0.078321</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>0.035070</td>\n",
       "      <td>0.097390</td>\n",
       "      <td>0.096591</td>\n",
       "      <td>0.108668</td>\n",
       "      <td>0.137098</td>\n",
       "      <td>0.006913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12058</th>\n",
       "      <td>0.101539</td>\n",
       "      <td>0.069730</td>\n",
       "      <td>0.045164</td>\n",
       "      <td>0.060069</td>\n",
       "      <td>0.155231</td>\n",
       "      <td>0.136302</td>\n",
       "      <td>0.163997</td>\n",
       "      <td>0.120017</td>\n",
       "      <td>0.127082</td>\n",
       "      <td>0.204744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180674</td>\n",
       "      <td>0.085758</td>\n",
       "      <td>0.070178</td>\n",
       "      <td>0.019658</td>\n",
       "      <td>0.030497</td>\n",
       "      <td>0.107647</td>\n",
       "      <td>0.103848</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>0.160554</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12059</th>\n",
       "      <td>0.107050</td>\n",
       "      <td>0.064986</td>\n",
       "      <td>0.039802</td>\n",
       "      <td>0.075908</td>\n",
       "      <td>0.159723</td>\n",
       "      <td>0.145168</td>\n",
       "      <td>0.161572</td>\n",
       "      <td>0.128852</td>\n",
       "      <td>0.103631</td>\n",
       "      <td>0.201460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191409</td>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.078486</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.098957</td>\n",
       "      <td>0.106344</td>\n",
       "      <td>0.129314</td>\n",
       "      <td>0.159057</td>\n",
       "      <td>0.013488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12060 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.710591  0.740873  0.547199  0.741455  0.773017  0.802497  0.744242   \n",
       "1      0.723895  0.744900  0.569207  0.745544  0.800938  0.823221  0.753272   \n",
       "2      0.694096  0.701866  0.555848  0.756330  0.802126  0.818500  0.775430   \n",
       "3      0.688762  0.705396  0.569178  0.762945  0.813941  0.816999  0.775064   \n",
       "4      0.711768  0.699094  0.559043  0.757788  0.798340  0.795479  0.752978   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12055  0.064527  0.081608  0.050122  0.084155  0.177531  0.145549  0.169727   \n",
       "12056  0.075095  0.067554  0.060098  0.066780  0.183105  0.147513  0.168850   \n",
       "12057  0.094642  0.062495  0.052516  0.053114  0.171743  0.149151  0.165863   \n",
       "12058  0.101539  0.069730  0.045164  0.060069  0.155231  0.136302  0.163997   \n",
       "12059  0.107050  0.064986  0.039802  0.075908  0.159723  0.145168  0.161572   \n",
       "\n",
       "            7         8         9    ...       291       292       293  \\\n",
       "0      0.580900  0.589981  0.634474  ...  0.600817  0.554528  0.549675   \n",
       "1      0.592454  0.622624  0.626670  ...  0.583271  0.560188  0.538886   \n",
       "2      0.586418  0.631961  0.666377  ...  0.555129  0.551880  0.535658   \n",
       "3      0.578164  0.644569  0.667846  ...  0.559803  0.552768  0.529465   \n",
       "4      0.590233  0.642330  0.699525  ...  0.550624  0.561540  0.532658   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "12055  0.128819  0.122197  0.191824  ...  0.157467  0.136246  0.099779   \n",
       "12056  0.127318  0.119356  0.189179  ...  0.178495  0.127205  0.079941   \n",
       "12057  0.123184  0.120258  0.183513  ...  0.191447  0.088844  0.078321   \n",
       "12058  0.120017  0.127082  0.204744  ...  0.180674  0.085758  0.070178   \n",
       "12059  0.128852  0.103631  0.201460  ...  0.191409  0.112069  0.078486   \n",
       "\n",
       "            294       295       296       297       298       299       300  \n",
       "0      0.525217  0.539929  0.551142  0.513436  0.544774  0.549715  0.328776  \n",
       "1      0.550928  0.555804  0.562092  0.520488  0.560097  0.575321  0.348507  \n",
       "2      0.569941  0.527941  0.582085  0.552601  0.549623  0.598872  0.356306  \n",
       "3      0.619179  0.526930  0.603167  0.557375  0.530285  0.627519  0.363066  \n",
       "4      0.630660  0.540437  0.646442  0.538977  0.502453  0.629111  0.369014  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "12055  0.025751  0.063447  0.102131  0.066000  0.109455  0.120781  0.003857  \n",
       "12056  0.025132  0.039449  0.099350  0.068147  0.103810  0.133884  0.003754  \n",
       "12057  0.030813  0.035070  0.097390  0.096591  0.108668  0.137098  0.006913  \n",
       "12058  0.019658  0.030497  0.107647  0.103848  0.122555  0.160554  0.002085  \n",
       "12059  0.012833  0.015417  0.098957  0.106344  0.129314  0.159057  0.013488  \n",
       "\n",
       "[12060 rows x 301 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(scaler.fit_transform(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.71059109 0.74087299 0.54719862 ... 0.51343603 0.5447736  0.54971503]\n",
      " [0.72389517 0.74489977 0.56920719 ... 0.5204876  0.56009676 0.57532133]\n",
      " [0.69409605 0.70186596 0.55584757 ... 0.55260117 0.54962349 0.59887151]\n",
      " ...\n",
      " [0.09464213 0.06249501 0.05251563 ... 0.09659131 0.10866754 0.13709828]\n",
      " [0.1015391  0.06973048 0.04516388 ... 0.10384841 0.12255479 0.16055397]\n",
      " [0.10704967 0.0649856  0.03980225 ... 0.1063437  0.12931391 0.15905747]]\n",
      "[0.32877552 0.34850738 0.35630642 ... 0.00691256 0.0020845  0.01348835]\n"
     ]
    }
   ],
   "source": [
    "y=data.iloc[:,300].values\n",
    "tempdata=data.iloc[:,:-1]\n",
    "x=tempdata.values\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.5,shuffle=False,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = tf.keras.Sequential()\n",
    "from sklearn.metrics import r2_score \n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, activation='relu',kernel_regularizer=l2(0.001),kernel_initializer='normal', input_shape=(300,)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(150, activation='relu', kernel_regularizer=l2(0.001),kernel_initializer='normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu',kernel_regularizer=l2(0.001), kernel_initializer='normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(50, activation='relu', kernel_regularizer=l2(0.001),kernel_initializer='normal'))\n",
    "# # model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='relu', kernel_regularizer=l2(0.001),kernel_initializer='normal'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(1,  activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 156,641\n",
      "Trainable params: 156,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.0001,momentum=0.99)\n",
    "model.compile( loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "95/95 - 1s - loss: 0.2015 - val_loss: 0.0823\n",
      "Epoch 2/100\n",
      "95/95 - 0s - loss: 0.0512 - val_loss: 0.0444\n",
      "Epoch 3/100\n",
      "95/95 - 0s - loss: 0.0299 - val_loss: 0.0387\n",
      "Epoch 4/100\n",
      "95/95 - 0s - loss: 0.0252 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "95/95 - 0s - loss: 0.0232 - val_loss: 0.0405\n",
      "Epoch 6/100\n",
      "95/95 - 0s - loss: 0.0223 - val_loss: 0.0397\n",
      "Epoch 7/100\n",
      "95/95 - 0s - loss: 0.0220 - val_loss: 0.0384\n",
      "Epoch 8/100\n",
      "95/95 - 0s - loss: 0.0213 - val_loss: 0.0391\n",
      "Epoch 9/100\n",
      "95/95 - 0s - loss: 0.0211 - val_loss: 0.0559\n",
      "Epoch 10/100\n",
      "95/95 - 0s - loss: 0.0214 - val_loss: 0.0533\n",
      "Epoch 11/100\n",
      "95/95 - 0s - loss: 0.0208 - val_loss: 0.0442\n",
      "Epoch 12/100\n",
      "95/95 - 0s - loss: 0.0206 - val_loss: 0.0415\n",
      "Epoch 13/100\n",
      "95/95 - 0s - loss: 0.0207 - val_loss: 0.0497\n",
      "Epoch 14/100\n",
      "95/95 - 0s - loss: 0.0207 - val_loss: 0.0440\n",
      "Epoch 15/100\n",
      "95/95 - 0s - loss: 0.0204 - val_loss: 0.0470\n",
      "Epoch 16/100\n",
      "95/95 - 0s - loss: 0.0204 - val_loss: 0.0443\n",
      "Epoch 17/100\n",
      "95/95 - 0s - loss: 0.0201 - val_loss: 0.0445\n",
      "Epoch 18/100\n",
      "95/95 - 0s - loss: 0.0203 - val_loss: 0.0485\n",
      "Epoch 19/100\n",
      "95/95 - 0s - loss: 0.0198 - val_loss: 0.0436\n",
      "Epoch 20/100\n",
      "95/95 - 0s - loss: 0.0210 - val_loss: 0.0516\n",
      "Epoch 21/100\n",
      "95/95 - 0s - loss: 0.0202 - val_loss: 0.0417\n",
      "Epoch 22/100\n",
      "95/95 - 0s - loss: 0.0192 - val_loss: 0.0517\n",
      "Epoch 23/100\n",
      "95/95 - 0s - loss: 0.0183 - val_loss: 0.0514\n",
      "Epoch 24/100\n",
      "95/95 - 0s - loss: 0.0175 - val_loss: 0.0471\n",
      "Epoch 25/100\n",
      "95/95 - 0s - loss: 0.0172 - val_loss: 0.0535\n",
      "Epoch 26/100\n",
      "95/95 - 0s - loss: 0.0160 - val_loss: 0.0460\n",
      "Epoch 27/100\n",
      "95/95 - 0s - loss: 0.0156 - val_loss: 0.0431\n",
      "Epoch 28/100\n",
      "95/95 - 0s - loss: 0.0144 - val_loss: 0.0529\n",
      "Epoch 29/100\n",
      "95/95 - 0s - loss: 0.0141 - val_loss: 0.0466\n",
      "Epoch 30/100\n",
      "95/95 - 0s - loss: 0.0140 - val_loss: 0.0475\n",
      "Epoch 31/100\n",
      "95/95 - 0s - loss: 0.0135 - val_loss: 0.0501\n",
      "Epoch 32/100\n",
      "95/95 - 0s - loss: 0.0129 - val_loss: 0.0509\n",
      "Epoch 33/100\n",
      "95/95 - 0s - loss: 0.0135 - val_loss: 0.0487\n",
      "Epoch 34/100\n",
      "95/95 - 0s - loss: 0.0131 - val_loss: 0.0433\n",
      "Epoch 35/100\n",
      "95/95 - 0s - loss: 0.0124 - val_loss: 0.0524\n",
      "Epoch 36/100\n",
      "95/95 - 0s - loss: 0.0121 - val_loss: 0.0412\n",
      "Epoch 37/100\n",
      "95/95 - 0s - loss: 0.0125 - val_loss: 0.0383\n",
      "Epoch 38/100\n",
      "95/95 - 0s - loss: 0.0124 - val_loss: 0.0440\n",
      "Epoch 39/100\n",
      "95/95 - 0s - loss: 0.0121 - val_loss: 0.0419\n",
      "Epoch 40/100\n",
      "95/95 - 0s - loss: 0.0116 - val_loss: 0.0514\n",
      "Epoch 41/100\n",
      "95/95 - 0s - loss: 0.0112 - val_loss: 0.0410\n",
      "Epoch 42/100\n",
      "95/95 - 0s - loss: 0.0110 - val_loss: 0.0397\n",
      "Epoch 43/100\n",
      "95/95 - 0s - loss: 0.0113 - val_loss: 0.0411\n",
      "Epoch 44/100\n",
      "95/95 - 0s - loss: 0.0111 - val_loss: 0.0483\n",
      "Epoch 45/100\n",
      "95/95 - 0s - loss: 0.0112 - val_loss: 0.0403\n",
      "Epoch 46/100\n",
      "95/95 - 0s - loss: 0.0106 - val_loss: 0.0473\n",
      "Epoch 47/100\n",
      "95/95 - 0s - loss: 0.0108 - val_loss: 0.0459\n",
      "Epoch 48/100\n",
      "95/95 - 0s - loss: 0.0104 - val_loss: 0.0464\n",
      "Epoch 49/100\n",
      "95/95 - 0s - loss: 0.0107 - val_loss: 0.0472\n",
      "Epoch 50/100\n",
      "95/95 - 0s - loss: 0.0104 - val_loss: 0.0411\n",
      "Epoch 51/100\n",
      "95/95 - 0s - loss: 0.0102 - val_loss: 0.0394\n",
      "Epoch 52/100\n",
      "95/95 - 0s - loss: 0.0107 - val_loss: 0.0372\n",
      "Epoch 53/100\n",
      "95/95 - 0s - loss: 0.0104 - val_loss: 0.0455\n",
      "Epoch 54/100\n",
      "95/95 - 0s - loss: 0.0099 - val_loss: 0.0417\n",
      "Epoch 55/100\n",
      "95/95 - 0s - loss: 0.0101 - val_loss: 0.0376\n",
      "Epoch 56/100\n",
      "95/95 - 0s - loss: 0.0100 - val_loss: 0.0383\n",
      "Epoch 57/100\n",
      "95/95 - 0s - loss: 0.0102 - val_loss: 0.0396\n",
      "Epoch 58/100\n",
      "95/95 - 0s - loss: 0.0100 - val_loss: 0.0415\n",
      "Epoch 59/100\n",
      "95/95 - 0s - loss: 0.0094 - val_loss: 0.0392\n",
      "Epoch 60/100\n",
      "95/95 - 0s - loss: 0.0102 - val_loss: 0.0425\n",
      "Epoch 61/100\n",
      "95/95 - 0s - loss: 0.0096 - val_loss: 0.0363\n",
      "Epoch 62/100\n",
      "95/95 - 0s - loss: 0.0099 - val_loss: 0.0366\n",
      "Epoch 63/100\n",
      "95/95 - 0s - loss: 0.0094 - val_loss: 0.0387\n",
      "Epoch 64/100\n",
      "95/95 - 0s - loss: 0.0090 - val_loss: 0.0377\n",
      "Epoch 65/100\n",
      "95/95 - 0s - loss: 0.0091 - val_loss: 0.0415\n",
      "Epoch 66/100\n",
      "95/95 - 0s - loss: 0.0097 - val_loss: 0.0478\n",
      "Epoch 67/100\n",
      "95/95 - 0s - loss: 0.0096 - val_loss: 0.0414\n",
      "Epoch 68/100\n",
      "95/95 - 0s - loss: 0.0095 - val_loss: 0.0351\n",
      "Epoch 69/100\n",
      "95/95 - 0s - loss: 0.0105 - val_loss: 0.0369\n",
      "Epoch 70/100\n",
      "95/95 - 0s - loss: 0.0091 - val_loss: 0.0436\n",
      "Epoch 71/100\n",
      "95/95 - 0s - loss: 0.0094 - val_loss: 0.0380\n",
      "Epoch 72/100\n",
      "95/95 - 0s - loss: 0.0095 - val_loss: 0.0364\n",
      "Epoch 73/100\n",
      "95/95 - 0s - loss: 0.0088 - val_loss: 0.0354\n",
      "Epoch 74/100\n",
      "95/95 - 0s - loss: 0.0091 - val_loss: 0.0323\n",
      "Epoch 75/100\n",
      "95/95 - 0s - loss: 0.0087 - val_loss: 0.0377\n",
      "Epoch 76/100\n",
      "95/95 - 0s - loss: 0.0088 - val_loss: 0.0429\n",
      "Epoch 77/100\n",
      "95/95 - 0s - loss: 0.0089 - val_loss: 0.0369\n",
      "Epoch 78/100\n",
      "95/95 - 0s - loss: 0.0086 - val_loss: 0.0420\n",
      "Epoch 79/100\n",
      "95/95 - 0s - loss: 0.0091 - val_loss: 0.0425\n",
      "Epoch 80/100\n",
      "95/95 - 0s - loss: 0.0092 - val_loss: 0.0360\n",
      "Epoch 81/100\n",
      "95/95 - 0s - loss: 0.0087 - val_loss: 0.0314\n",
      "Epoch 82/100\n",
      "95/95 - 0s - loss: 0.0086 - val_loss: 0.0435\n",
      "Epoch 83/100\n",
      "95/95 - 0s - loss: 0.0084 - val_loss: 0.0318\n",
      "Epoch 84/100\n",
      "95/95 - 0s - loss: 0.0087 - val_loss: 0.0370\n",
      "Epoch 85/100\n",
      "95/95 - 0s - loss: 0.0087 - val_loss: 0.0329\n",
      "Epoch 86/100\n",
      "95/95 - 0s - loss: 0.0082 - val_loss: 0.0324\n",
      "Epoch 87/100\n",
      "95/95 - 0s - loss: 0.0085 - val_loss: 0.0338\n",
      "Epoch 88/100\n",
      "95/95 - 0s - loss: 0.0083 - val_loss: 0.0323\n",
      "Epoch 89/100\n",
      "95/95 - 0s - loss: 0.0084 - val_loss: 0.0346\n",
      "Epoch 90/100\n",
      "95/95 - 0s - loss: 0.0082 - val_loss: 0.0331\n",
      "Epoch 91/100\n",
      "95/95 - 0s - loss: 0.0082 - val_loss: 0.0362\n",
      "Epoch 92/100\n",
      "95/95 - 0s - loss: 0.0084 - val_loss: 0.0323\n",
      "Epoch 93/100\n",
      "95/95 - 0s - loss: 0.0081 - val_loss: 0.0311\n",
      "Epoch 94/100\n",
      "95/95 - 0s - loss: 0.0082 - val_loss: 0.0355\n",
      "Epoch 95/100\n",
      "95/95 - 1s - loss: 0.0081 - val_loss: 0.0333\n",
      "Epoch 96/100\n",
      "95/95 - 0s - loss: 0.0088 - val_loss: 0.0386\n",
      "Epoch 97/100\n",
      "95/95 - 1s - loss: 0.0079 - val_loss: 0.0284\n",
      "Epoch 98/100\n",
      "95/95 - 0s - loss: 0.0084 - val_loss: 0.0309\n",
      "Epoch 99/100\n",
      "95/95 - 0s - loss: 0.0080 - val_loss: 0.0369\n",
      "Epoch 100/100\n",
      "95/95 - 1s - loss: 0.0079 - val_loss: 0.0340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0fb467d700>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, verbose=2,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score _ Train data :  0.8175526442421418\n",
      "MSE: 0.034, RMSE: 0.185\n"
     ]
    }
   ],
   "source": [
    "y_train_val=model.predict(X_train)\n",
    "error2 = model.evaluate(X_test, Y_test, verbose=0)\n",
    "r22 = r2_score(y_train_val,Y_train ) \n",
    "print('r2 score _ Train data : ', r22) \n",
    "print('MSE: %.3f, RMSE: %.3f' % (error2, math.sqrt(error2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score Test data:  -0.5457242660821329\n",
      "MSE: 0.034, RMSE: 0.185\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "# evaluate the model\n",
    "error = model.evaluate(X_test, Y_test, verbose=0)\n",
    "r2 = r2_score(Y_test,Y_pred ) \n",
    "print('r2 score Test data: ', r22) \n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, math.sqrt(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Rg_predicted(Test)')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_train_val,Y_train,'o',label='R2 = %.4f' %(r22)) \n",
    "plt.legend()\n",
    "plt.title('Rg_predicted vs rg_actual - Test Data')\n",
    "plt.xlabel('Rg_actual(Test)  ')\n",
    "plt.ylabel('Rg_predicted(Test)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
